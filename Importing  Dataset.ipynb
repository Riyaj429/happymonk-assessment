{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pydataset.data(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "1           5.1          3.5           1.4          0.2  setosa\n",
       "2           4.9          3.0           1.4          0.2  setosa\n",
       "3           4.7          3.2           1.3          0.2  setosa\n",
       "4           4.6          3.1           1.5          0.2  setosa\n",
       "5           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "labels = le.fit_transform(df['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Species'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"]]\n",
    "y = df[['Species']]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['Petal.Width'], df['Species'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnModel = KNeighborsClassifier(n_neighbors=3)\n",
    "knnModel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnModel.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.python.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.backend import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "#CREATING THE ANN AS SEQUENCE OF LAYERS\n",
    "ann = Sequential()\n",
    "\n",
    "#ADD FIRST HIDDEN LAYER WITH 30 NEURONS, THE INPUT LAYERS WILL BE ADDED AUTOAMTICALLY,\n",
    "ann.add(Dense(units = 30,activation = 'relu'))\n",
    "ann.add(BatchNormalization())\n",
    "ann.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "#ADDING OUTPUT LAYER WITH 1 NEURON, AS THIS IS BINARY CLASSIFICATION\n",
    "ann.add(Dense(units = 1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 355ms/step\n"
     ]
    }
   ],
   "source": [
    "#now testing for test data\n",
    "\n",
    "y_pred = ann.predict(x_test)\n",
    "\n",
    "#converting values\n",
    "y_pred = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  7  0]\n",
      " [ 0 11  0]\n",
      " [ 0 12  0]]\n",
      "score is 0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "print(cm)\n",
    "print(\"score is\",score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.37      1.00      0.54        11\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.37        30\n",
      "   macro avg       0.12      0.33      0.18        30\n",
      "weighted avg       0.13      0.37      0.20        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating heatmap of confusion matrix \n",
    "import seaborn as sns\n",
    "plt.figure(figsize=[14,7])\n",
    "sns.heatmap(cm,annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# creating the ann as sequence of layers\n",
    "\n",
    "ann = Sequential()\n",
    "\n",
    "#adding first hidden layer with 30 neurons,the input layer will be added automatically\n",
    "\n",
    "ann.add(Dense(units=30,activation='softmax'))\n",
    "ann.add(BatchNormalization())\n",
    "ann.add(Dropout(0.5))\n",
    "\n",
    "# adding output layer with 1 neuron, as this a binary classification\n",
    "\n",
    "ann.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 1s 77ms/step - loss: 0.5823 - accuracy: 0.4250 - val_loss: 0.6696 - val_accuracy: 0.3667\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5293 - accuracy: 0.5167 - val_loss: 0.6455 - val_accuracy: 0.3667\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4387 - accuracy: 0.5083 - val_loss: 0.6214 - val_accuracy: 0.3667\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3801 - accuracy: 0.5750 - val_loss: 0.5971 - val_accuracy: 0.3667\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3048 - accuracy: 0.6167 - val_loss: 0.5739 - val_accuracy: 0.3667\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2410 - accuracy: 0.6083 - val_loss: 0.5506 - val_accuracy: 0.3667\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0999 - accuracy: 0.6167 - val_loss: 0.5273 - val_accuracy: 0.3667\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1231 - accuracy: 0.6417 - val_loss: 0.5042 - val_accuracy: 0.3667\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0667 - accuracy: 0.6500 - val_loss: 0.4816 - val_accuracy: 0.3667\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -0.0183 - accuracy: 0.6417 - val_loss: 0.4596 - val_accuracy: 0.3667\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -0.1237 - accuracy: 0.6667 - val_loss: 0.4370 - val_accuracy: 0.3667\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -0.1646 - accuracy: 0.6750 - val_loss: 0.4141 - val_accuracy: 0.3667\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -0.1824 - accuracy: 0.6833 - val_loss: 0.3912 - val_accuracy: 0.3667\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -0.2666 - accuracy: 0.6833 - val_loss: 0.3675 - val_accuracy: 0.3667\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -0.3125 - accuracy: 0.6500 - val_loss: 0.3432 - val_accuracy: 0.3667\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.4143 - accuracy: 0.6750 - val_loss: 0.3176 - val_accuracy: 0.3667\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -0.4010 - accuracy: 0.6667 - val_loss: 0.2923 - val_accuracy: 0.3667\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -0.4851 - accuracy: 0.6750 - val_loss: 0.2657 - val_accuracy: 0.3667\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -0.4980 - accuracy: 0.6833 - val_loss: 0.2393 - val_accuracy: 0.3667\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -0.6611 - accuracy: 0.6750 - val_loss: 0.2125 - val_accuracy: 0.3667\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -0.6833 - accuracy: 0.6833 - val_loss: 0.1850 - val_accuracy: 0.3667\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -0.7615 - accuracy: 0.6750 - val_loss: 0.1567 - val_accuracy: 0.3667\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -0.8453 - accuracy: 0.6833 - val_loss: 0.1284 - val_accuracy: 0.3667\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -0.9431 - accuracy: 0.6833 - val_loss: 0.0994 - val_accuracy: 0.3667\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -0.9225 - accuracy: 0.6750 - val_loss: 0.0700 - val_accuracy: 0.3667\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -0.9710 - accuracy: 0.6833 - val_loss: 0.0405 - val_accuracy: 0.3667\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -1.0101 - accuracy: 0.6833 - val_loss: 0.0119 - val_accuracy: 0.3667\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -1.0201 - accuracy: 0.6833 - val_loss: -0.0180 - val_accuracy: 0.3667\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -1.1435 - accuracy: 0.6833 - val_loss: -0.0476 - val_accuracy: 0.3667\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -1.1604 - accuracy: 0.6833 - val_loss: -0.0767 - val_accuracy: 0.3667\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -1.2939 - accuracy: 0.6750 - val_loss: -0.1062 - val_accuracy: 0.3667\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -1.3095 - accuracy: 0.6833 - val_loss: -0.1367 - val_accuracy: 0.3667\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -1.4508 - accuracy: 0.6833 - val_loss: -0.1674 - val_accuracy: 0.3667\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -1.3342 - accuracy: 0.6833 - val_loss: -0.1991 - val_accuracy: 0.3667\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -1.5071 - accuracy: 0.6833 - val_loss: -0.2302 - val_accuracy: 0.3667\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -1.6500 - accuracy: 0.6833 - val_loss: -0.2625 - val_accuracy: 0.3667\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -1.5353 - accuracy: 0.6667 - val_loss: -0.2939 - val_accuracy: 0.3667\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -1.6620 - accuracy: 0.6833 - val_loss: -0.3264 - val_accuracy: 0.3667\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -1.7073 - accuracy: 0.6833 - val_loss: -0.3600 - val_accuracy: 0.3667\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -1.6656 - accuracy: 0.6750 - val_loss: -0.3941 - val_accuracy: 0.3667\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -1.8578 - accuracy: 0.6833 - val_loss: -0.4281 - val_accuracy: 0.3667\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: -1.8733 - accuracy: 0.6833 - val_loss: -0.4623 - val_accuracy: 0.3667\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -1.9980 - accuracy: 0.6833 - val_loss: -0.4973 - val_accuracy: 0.3667\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -2.0086 - accuracy: 0.6833 - val_loss: -0.5327 - val_accuracy: 0.3667\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -2.0312 - accuracy: 0.6833 - val_loss: -0.5686 - val_accuracy: 0.3667\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -2.1001 - accuracy: 0.6833 - val_loss: -0.6076 - val_accuracy: 0.3667\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -2.1868 - accuracy: 0.6750 - val_loss: -0.6476 - val_accuracy: 0.3667\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -2.2417 - accuracy: 0.6833 - val_loss: -0.6878 - val_accuracy: 0.3667\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -2.5573 - accuracy: 0.6833 - val_loss: -0.7295 - val_accuracy: 0.3667\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -2.5265 - accuracy: 0.6833 - val_loss: -0.7728 - val_accuracy: 0.3667\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -2.4426 - accuracy: 0.6667 - val_loss: -0.8178 - val_accuracy: 0.3667\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -2.6896 - accuracy: 0.6833 - val_loss: -0.8638 - val_accuracy: 0.3667\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -2.7185 - accuracy: 0.6833 - val_loss: -0.9112 - val_accuracy: 0.3667\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -2.8176 - accuracy: 0.6833 - val_loss: -0.9589 - val_accuracy: 0.3667\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -3.2064 - accuracy: 0.6833 - val_loss: -1.0076 - val_accuracy: 0.3667\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -2.9070 - accuracy: 0.6833 - val_loss: -1.0542 - val_accuracy: 0.3667\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -3.0146 - accuracy: 0.6833 - val_loss: -1.1023 - val_accuracy: 0.3667\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -3.0172 - accuracy: 0.6833 - val_loss: -1.1489 - val_accuracy: 0.3667\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -3.4655 - accuracy: 0.6833 - val_loss: -1.1947 - val_accuracy: 0.3667\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -3.2298 - accuracy: 0.6833 - val_loss: -1.2419 - val_accuracy: 0.3667\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -3.5716 - accuracy: 0.6833 - val_loss: -1.2900 - val_accuracy: 0.3667\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -3.6255 - accuracy: 0.6833 - val_loss: -1.3399 - val_accuracy: 0.3667\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -3.7415 - accuracy: 0.6833 - val_loss: -1.3935 - val_accuracy: 0.3667\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -3.6523 - accuracy: 0.6667 - val_loss: -1.4494 - val_accuracy: 0.3667\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -3.7256 - accuracy: 0.6833 - val_loss: -1.5106 - val_accuracy: 0.3667\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -3.9299 - accuracy: 0.6833 - val_loss: -1.5738 - val_accuracy: 0.3667\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -3.6332 - accuracy: 0.6833 - val_loss: -1.6401 - val_accuracy: 0.3667\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -3.9298 - accuracy: 0.6833 - val_loss: -1.7076 - val_accuracy: 0.3667\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -4.0121 - accuracy: 0.6833 - val_loss: -1.7726 - val_accuracy: 0.3667\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -4.1521 - accuracy: 0.6833 - val_loss: -1.8340 - val_accuracy: 0.3667\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -4.3389 - accuracy: 0.6833 - val_loss: -1.8999 - val_accuracy: 0.3667\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -4.4860 - accuracy: 0.6667 - val_loss: -1.9668 - val_accuracy: 0.3667\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -4.4173 - accuracy: 0.6833 - val_loss: -2.0379 - val_accuracy: 0.3667\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -4.9172 - accuracy: 0.6833 - val_loss: -2.1151 - val_accuracy: 0.3667\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -4.4082 - accuracy: 0.6833 - val_loss: -2.1970 - val_accuracy: 0.3667\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -4.7641 - accuracy: 0.6833 - val_loss: -2.2741 - val_accuracy: 0.3667\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -4.8471 - accuracy: 0.6833 - val_loss: -2.3519 - val_accuracy: 0.3667\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -4.9448 - accuracy: 0.6750 - val_loss: -2.4305 - val_accuracy: 0.3667\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -5.0524 - accuracy: 0.6833 - val_loss: -2.5096 - val_accuracy: 0.3667\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -5.4339 - accuracy: 0.6833 - val_loss: -2.5947 - val_accuracy: 0.3667\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -5.4324 - accuracy: 0.6833 - val_loss: -2.6787 - val_accuracy: 0.3667\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -5.4234 - accuracy: 0.6833 - val_loss: -2.7689 - val_accuracy: 0.3667\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -5.4047 - accuracy: 0.6833 - val_loss: -2.8592 - val_accuracy: 0.3667\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -5.9190 - accuracy: 0.6833 - val_loss: -2.9530 - val_accuracy: 0.3667\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -6.2592 - accuracy: 0.6833 - val_loss: -3.0455 - val_accuracy: 0.3667\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -5.4289 - accuracy: 0.6833 - val_loss: -3.1448 - val_accuracy: 0.3667\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -5.8270 - accuracy: 0.6833 - val_loss: -3.2549 - val_accuracy: 0.3667\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -5.9747 - accuracy: 0.6750 - val_loss: -3.3620 - val_accuracy: 0.3667\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -6.1224 - accuracy: 0.6833 - val_loss: -3.4633 - val_accuracy: 0.3667\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -5.6140 - accuracy: 0.6833 - val_loss: -3.5673 - val_accuracy: 0.3667\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -6.4312 - accuracy: 0.6833 - val_loss: -3.6759 - val_accuracy: 0.3667\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -6.5919 - accuracy: 0.6833 - val_loss: -3.7845 - val_accuracy: 0.3667\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -6.7534 - accuracy: 0.6833 - val_loss: -3.9077 - val_accuracy: 0.3667\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -6.5631 - accuracy: 0.6833 - val_loss: -4.0366 - val_accuracy: 0.3667\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -7.0257 - accuracy: 0.6833 - val_loss: -4.1609 - val_accuracy: 0.3667\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -7.5843 - accuracy: 0.6750 - val_loss: -4.2888 - val_accuracy: 0.3667\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -6.7823 - accuracy: 0.6833 - val_loss: -4.4072 - val_accuracy: 0.3667\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -7.3445 - accuracy: 0.6833 - val_loss: -4.5345 - val_accuracy: 0.3667\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -7.2706 - accuracy: 0.6833 - val_loss: -4.6627 - val_accuracy: 0.3667\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -7.5071 - accuracy: 0.6833 - val_loss: -4.8095 - val_accuracy: 0.3667\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -8.0020 - accuracy: 0.6833 - val_loss: -4.9507 - val_accuracy: 0.3667\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -8.0550 - accuracy: 0.6833 - val_loss: -5.1041 - val_accuracy: 0.3667\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -7.7401 - accuracy: 0.6833 - val_loss: -5.2554 - val_accuracy: 0.3667\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -8.1548 - accuracy: 0.6833 - val_loss: -5.4151 - val_accuracy: 0.3667\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -8.1123 - accuracy: 0.6750 - val_loss: -5.5727 - val_accuracy: 0.3667\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -8.2143 - accuracy: 0.6833 - val_loss: -5.7275 - val_accuracy: 0.3667\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -8.4473 - accuracy: 0.6833 - val_loss: -5.8762 - val_accuracy: 0.3667\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -8.7107 - accuracy: 0.6833 - val_loss: -6.0377 - val_accuracy: 0.3667\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -9.0925 - accuracy: 0.6750 - val_loss: -6.2065 - val_accuracy: 0.3667\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -7.9052 - accuracy: 0.6750 - val_loss: -6.3967 - val_accuracy: 0.3667\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -8.8306 - accuracy: 0.6750 - val_loss: -6.5687 - val_accuracy: 0.3667\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -9.5332 - accuracy: 0.6833 - val_loss: -6.7328 - val_accuracy: 0.3667\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -9.2530 - accuracy: 0.6500 - val_loss: -6.9261 - val_accuracy: 0.3667\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -9.3931 - accuracy: 0.6667 - val_loss: -7.1123 - val_accuracy: 0.3667\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -10.4425 - accuracy: 0.6750 - val_loss: -7.3348 - val_accuracy: 0.3667\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -9.9048 - accuracy: 0.6833 - val_loss: -7.5373 - val_accuracy: 0.3667\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -9.8410 - accuracy: 0.6833 - val_loss: -7.7201 - val_accuracy: 0.3667\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -9.9368 - accuracy: 0.6833 - val_loss: -7.9162 - val_accuracy: 0.3667\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: -10.8305 - accuracy: 0.6833 - val_loss: -8.0764 - val_accuracy: 0.3667\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -9.0354 - accuracy: 0.6750 - val_loss: -8.2593 - val_accuracy: 0.3667\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -10.1207 - accuracy: 0.6750 - val_loss: -8.4655 - val_accuracy: 0.3667\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -10.5072 - accuracy: 0.6833 - val_loss: -8.6834 - val_accuracy: 0.3667\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -10.5485 - accuracy: 0.6750 - val_loss: -8.9249 - val_accuracy: 0.3667\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -10.9562 - accuracy: 0.6833 - val_loss: -9.1764 - val_accuracy: 0.3667\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -12.0950 - accuracy: 0.6750 - val_loss: -9.3950 - val_accuracy: 0.3667\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -11.4062 - accuracy: 0.6750 - val_loss: -9.6103 - val_accuracy: 0.3667\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -11.0833 - accuracy: 0.6750 - val_loss: -9.8264 - val_accuracy: 0.4000\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -11.2401 - accuracy: 0.6750 - val_loss: -10.0623 - val_accuracy: 0.4000\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -12.0031 - accuracy: 0.6833 - val_loss: -10.2604 - val_accuracy: 0.4000\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -10.9110 - accuracy: 0.6750 - val_loss: -10.4741 - val_accuracy: 0.4333\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -12.8371 - accuracy: 0.6833 - val_loss: -10.6570 - val_accuracy: 0.4333\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -12.2486 - accuracy: 0.6500 - val_loss: -10.8778 - val_accuracy: 0.4333\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -12.6522 - accuracy: 0.6583 - val_loss: -11.1118 - val_accuracy: 0.4667\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -12.2185 - accuracy: 0.6833 - val_loss: -11.3944 - val_accuracy: 0.4667\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -12.8338 - accuracy: 0.6750 - val_loss: -11.6546 - val_accuracy: 0.5000\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -13.0158 - accuracy: 0.6833 - val_loss: -11.8705 - val_accuracy: 0.5000\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -12.4895 - accuracy: 0.6750 - val_loss: -12.1328 - val_accuracy: 0.5333\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -12.8339 - accuracy: 0.6167 - val_loss: -12.4631 - val_accuracy: 0.5667\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -13.0153 - accuracy: 0.6833 - val_loss: -12.7603 - val_accuracy: 0.5667\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -13.1991 - accuracy: 0.6667 - val_loss: -12.9981 - val_accuracy: 0.6000\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -13.5845 - accuracy: 0.6750 - val_loss: -13.2093 - val_accuracy: 0.6000\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -13.9477 - accuracy: 0.6750 - val_loss: -13.4548 - val_accuracy: 0.6000\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -14.1851 - accuracy: 0.6833 - val_loss: -13.6605 - val_accuracy: 0.6000\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -14.0964 - accuracy: 0.6583 - val_loss: -13.9098 - val_accuracy: 0.6000\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -14.3938 - accuracy: 0.6833 - val_loss: -14.1742 - val_accuracy: 0.6000\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -13.9174 - accuracy: 0.6750 - val_loss: -14.4198 - val_accuracy: 0.6000\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -14.9106 - accuracy: 0.6750 - val_loss: -14.6733 - val_accuracy: 0.6000\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -14.9543 - accuracy: 0.6750 - val_loss: -14.9426 - val_accuracy: 0.6000\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -15.2283 - accuracy: 0.6833 - val_loss: -15.2278 - val_accuracy: 0.6000\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -16.1933 - accuracy: 0.6833 - val_loss: -15.5632 - val_accuracy: 0.6000\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -15.1109 - accuracy: 0.6750 - val_loss: -15.8918 - val_accuracy: 0.6000\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: -15.9233 - accuracy: 0.6583 - val_loss: -16.2712 - val_accuracy: 0.6000\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -15.8267 - accuracy: 0.6833 - val_loss: -16.6371 - val_accuracy: 0.6000\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -15.5495 - accuracy: 0.6833 - val_loss: -16.8769 - val_accuracy: 0.6000\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -15.5070 - accuracy: 0.6750 - val_loss: -17.1953 - val_accuracy: 0.6000\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -16.4208 - accuracy: 0.6583 - val_loss: -17.5537 - val_accuracy: 0.6000\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -16.9533 - accuracy: 0.6667 - val_loss: -17.7883 - val_accuracy: 0.6000\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -16.0412 - accuracy: 0.6417 - val_loss: -18.0947 - val_accuracy: 0.6000\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -17.3167 - accuracy: 0.6667 - val_loss: -18.3357 - val_accuracy: 0.6000\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -16.3929 - accuracy: 0.6667 - val_loss: -18.6166 - val_accuracy: 0.6000\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -17.3026 - accuracy: 0.6583 - val_loss: -18.9049 - val_accuracy: 0.6000\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -18.3490 - accuracy: 0.6500 - val_loss: -19.1887 - val_accuracy: 0.6000\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -17.2683 - accuracy: 0.6667 - val_loss: -19.5767 - val_accuracy: 0.6000\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -17.2163 - accuracy: 0.6750 - val_loss: -19.8964 - val_accuracy: 0.6000\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -17.8652 - accuracy: 0.6333 - val_loss: -20.2648 - val_accuracy: 0.6000\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -18.9826 - accuracy: 0.6667 - val_loss: -20.5646 - val_accuracy: 0.6000\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -18.9989 - accuracy: 0.6667 - val_loss: -20.8149 - val_accuracy: 0.6000\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -17.9428 - accuracy: 0.6667 - val_loss: -21.1370 - val_accuracy: 0.6000\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -18.2838 - accuracy: 0.6500 - val_loss: -21.4068 - val_accuracy: 0.6000\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -19.9691 - accuracy: 0.6500 - val_loss: -21.6645 - val_accuracy: 0.6000\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -18.7398 - accuracy: 0.6667 - val_loss: -21.9634 - val_accuracy: 0.6000\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -18.5599 - accuracy: 0.6667 - val_loss: -22.3337 - val_accuracy: 0.6000\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -19.8577 - accuracy: 0.6583 - val_loss: -22.6677 - val_accuracy: 0.6000\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -20.4883 - accuracy: 0.6583 - val_loss: -23.0224 - val_accuracy: 0.6000\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -18.3198 - accuracy: 0.6250 - val_loss: -23.3781 - val_accuracy: 0.6000\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -21.4349 - accuracy: 0.6750 - val_loss: -23.6794 - val_accuracy: 0.6000\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -21.4883 - accuracy: 0.6583 - val_loss: -23.9496 - val_accuracy: 0.6000\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -19.2369 - accuracy: 0.6500 - val_loss: -24.2612 - val_accuracy: 0.6000\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -20.1003 - accuracy: 0.6583 - val_loss: -24.6210 - val_accuracy: 0.6000\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -21.6389 - accuracy: 0.6583 - val_loss: -25.0110 - val_accuracy: 0.6000\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -21.3806 - accuracy: 0.6000 - val_loss: -25.4051 - val_accuracy: 0.6000\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -20.2013 - accuracy: 0.5833 - val_loss: -25.8158 - val_accuracy: 0.6000\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -21.5095 - accuracy: 0.6333 - val_loss: -26.2333 - val_accuracy: 0.6000\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -22.4135 - accuracy: 0.6500 - val_loss: -26.6805 - val_accuracy: 0.6000\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -22.5868 - accuracy: 0.6333 - val_loss: -27.0289 - val_accuracy: 0.6000\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -22.9512 - accuracy: 0.5750 - val_loss: -27.3717 - val_accuracy: 0.6000\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -22.6908 - accuracy: 0.6583 - val_loss: -27.5938 - val_accuracy: 0.6000\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -22.3533 - accuracy: 0.5833 - val_loss: -27.7390 - val_accuracy: 0.6000\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -23.5076 - accuracy: 0.6417 - val_loss: -28.0576 - val_accuracy: 0.6000\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: -23.4125 - accuracy: 0.5917 - val_loss: -28.3058 - val_accuracy: 0.6000\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -23.9848 - accuracy: 0.5833 - val_loss: -28.6916 - val_accuracy: 0.6000\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -24.0437 - accuracy: 0.6083 - val_loss: -28.9771 - val_accuracy: 0.6000\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -23.6603 - accuracy: 0.6417 - val_loss: -29.2062 - val_accuracy: 0.6000\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -24.4253 - accuracy: 0.6250 - val_loss: -29.5153 - val_accuracy: 0.6000\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -23.6032 - accuracy: 0.6500 - val_loss: -29.6539 - val_accuracy: 0.6000\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -26.1395 - accuracy: 0.6333 - val_loss: -29.8178 - val_accuracy: 0.6000\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -24.4350 - accuracy: 0.6250 - val_loss: -29.9735 - val_accuracy: 0.6000\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -23.7986 - accuracy: 0.6417 - val_loss: -30.3831 - val_accuracy: 0.6000\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -22.8871 - accuracy: 0.5750 - val_loss: -30.8598 - val_accuracy: 0.6000\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -24.6088 - accuracy: 0.5833 - val_loss: -31.5326 - val_accuracy: 0.6000\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -25.6575 - accuracy: 0.6000 - val_loss: -32.2344 - val_accuracy: 0.6000\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -25.3135 - accuracy: 0.6250 - val_loss: -32.7339 - val_accuracy: 0.6000\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -24.9778 - accuracy: 0.6583 - val_loss: -33.1200 - val_accuracy: 0.6000\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -26.1669 - accuracy: 0.6167 - val_loss: -33.3441 - val_accuracy: 0.6000\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -26.4514 - accuracy: 0.6250 - val_loss: -33.5329 - val_accuracy: 0.6000\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -24.8115 - accuracy: 0.6000 - val_loss: -33.6747 - val_accuracy: 0.6000\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -25.1738 - accuracy: 0.6250 - val_loss: -33.7882 - val_accuracy: 0.6000\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -27.5721 - accuracy: 0.5917 - val_loss: -33.9568 - val_accuracy: 0.6000\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -26.3796 - accuracy: 0.5750 - val_loss: -34.1357 - val_accuracy: 0.6000\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -27.3194 - accuracy: 0.6167 - val_loss: -34.4405 - val_accuracy: 0.6000\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -27.2581 - accuracy: 0.5500 - val_loss: -34.7836 - val_accuracy: 0.6000\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -27.6319 - accuracy: 0.5250 - val_loss: -35.4264 - val_accuracy: 0.6000\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -26.8323 - accuracy: 0.6333 - val_loss: -35.9460 - val_accuracy: 0.6000\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -28.8113 - accuracy: 0.6250 - val_loss: -36.3149 - val_accuracy: 0.6000\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -28.1453 - accuracy: 0.5833 - val_loss: -36.4686 - val_accuracy: 0.6000\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -27.4981 - accuracy: 0.6083 - val_loss: -36.6709 - val_accuracy: 0.6000\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -29.1853 - accuracy: 0.5750 - val_loss: -36.9413 - val_accuracy: 0.6000\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -29.5738 - accuracy: 0.5667 - val_loss: -37.1935 - val_accuracy: 0.6000\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -31.4826 - accuracy: 0.6667 - val_loss: -37.4769 - val_accuracy: 0.6000\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -28.4055 - accuracy: 0.6083 - val_loss: -37.7606 - val_accuracy: 0.6000\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -28.0216 - accuracy: 0.6167 - val_loss: -38.1228 - val_accuracy: 0.6000\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -29.3697 - accuracy: 0.6500 - val_loss: -38.4070 - val_accuracy: 0.6000\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: -30.4479 - accuracy: 0.6250 - val_loss: -38.5149 - val_accuracy: 0.6000\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -29.6261 - accuracy: 0.6167 - val_loss: -38.7527 - val_accuracy: 0.6000\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -31.4777 - accuracy: 0.6083 - val_loss: -38.9427 - val_accuracy: 0.6000\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -30.4586 - accuracy: 0.5833 - val_loss: -39.2189 - val_accuracy: 0.6000\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -30.9866 - accuracy: 0.5500 - val_loss: -39.7236 - val_accuracy: 0.6000\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -32.5330 - accuracy: 0.6083 - val_loss: -40.2927 - val_accuracy: 0.6000\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -30.9807 - accuracy: 0.5333 - val_loss: -40.7831 - val_accuracy: 0.6000\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -30.9919 - accuracy: 0.6000 - val_loss: -41.1442 - val_accuracy: 0.6000\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -32.5691 - accuracy: 0.5833 - val_loss: -41.4820 - val_accuracy: 0.6000\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -33.0001 - accuracy: 0.6250 - val_loss: -41.7443 - val_accuracy: 0.6000\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -31.7927 - accuracy: 0.5917 - val_loss: -42.0439 - val_accuracy: 0.6000\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -31.8346 - accuracy: 0.6000 - val_loss: -42.2497 - val_accuracy: 0.6000\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -33.2280 - accuracy: 0.5583 - val_loss: -42.6825 - val_accuracy: 0.6000\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -28.9557 - accuracy: 0.5000 - val_loss: -43.1236 - val_accuracy: 0.6000\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -31.9791 - accuracy: 0.5250 - val_loss: -43.8205 - val_accuracy: 0.6000\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -34.6923 - accuracy: 0.6417 - val_loss: -44.1273 - val_accuracy: 0.6000\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -32.7036 - accuracy: 0.6167 - val_loss: -44.2604 - val_accuracy: 0.6000\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -35.7718 - accuracy: 0.6083 - val_loss: -44.2625 - val_accuracy: 0.6000\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -35.0087 - accuracy: 0.5917 - val_loss: -44.3138 - val_accuracy: 0.6000\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -28.9421 - accuracy: 0.5333 - val_loss: -44.6349 - val_accuracy: 0.6000\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -33.3850 - accuracy: 0.5917 - val_loss: -44.8768 - val_accuracy: 0.6000\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -35.9671 - accuracy: 0.6417 - val_loss: -45.0431 - val_accuracy: 0.6000\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -32.9960 - accuracy: 0.5500 - val_loss: -45.2105 - val_accuracy: 0.6000\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -36.1772 - accuracy: 0.6333 - val_loss: -45.4629 - val_accuracy: 0.6000\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -33.4663 - accuracy: 0.5500 - val_loss: -45.8060 - val_accuracy: 0.6000\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -36.1043 - accuracy: 0.6167 - val_loss: -46.3596 - val_accuracy: 0.6000\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -35.4836 - accuracy: 0.5167 - val_loss: -46.9995 - val_accuracy: 0.6000\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -35.4595 - accuracy: 0.6333 - val_loss: -47.4755 - val_accuracy: 0.6000\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -37.5764 - accuracy: 0.5667 - val_loss: -47.8297 - val_accuracy: 0.6000\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -39.1974 - accuracy: 0.6000 - val_loss: -47.9225 - val_accuracy: 0.6000\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -36.2775 - accuracy: 0.5917 - val_loss: -48.1090 - val_accuracy: 0.6000\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -38.0974 - accuracy: 0.6000 - val_loss: -48.3130 - val_accuracy: 0.6000\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -39.1154 - accuracy: 0.6333 - val_loss: -48.4723 - val_accuracy: 0.6000\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -37.2574 - accuracy: 0.4917 - val_loss: -48.8224 - val_accuracy: 0.6000\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -36.2476 - accuracy: 0.6000 - val_loss: -49.2836 - val_accuracy: 0.6000\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -38.7636 - accuracy: 0.5417 - val_loss: -49.8052 - val_accuracy: 0.6000\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -38.3444 - accuracy: 0.6083 - val_loss: -50.3545 - val_accuracy: 0.6000\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -37.3382 - accuracy: 0.5083 - val_loss: -50.9407 - val_accuracy: 0.6000\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -37.3514 - accuracy: 0.5583 - val_loss: -51.3463 - val_accuracy: 0.6000\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -42.3073 - accuracy: 0.6333 - val_loss: -51.5256 - val_accuracy: 0.6000\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -39.3363 - accuracy: 0.6417 - val_loss: -51.5317 - val_accuracy: 0.6000\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -41.2297 - accuracy: 0.6083 - val_loss: -51.5213 - val_accuracy: 0.6000\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -41.4796 - accuracy: 0.6000 - val_loss: -51.5168 - val_accuracy: 0.6000\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: -39.9557 - accuracy: 0.6000 - val_loss: -51.5291 - val_accuracy: 0.6000\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -38.9673 - accuracy: 0.5667 - val_loss: -51.9050 - val_accuracy: 0.6000\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -42.0920 - accuracy: 0.5583 - val_loss: -52.3347 - val_accuracy: 0.6000\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -42.3276 - accuracy: 0.5250 - val_loss: -53.2143 - val_accuracy: 0.6000\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -41.7649 - accuracy: 0.5417 - val_loss: -53.9673 - val_accuracy: 0.6000\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -42.7186 - accuracy: 0.5750 - val_loss: -54.4441 - val_accuracy: 0.6000\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -41.8390 - accuracy: 0.6000 - val_loss: -54.7770 - val_accuracy: 0.6000\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -41.8211 - accuracy: 0.5417 - val_loss: -55.1436 - val_accuracy: 0.6000\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -41.3786 - accuracy: 0.6083 - val_loss: -55.2820 - val_accuracy: 0.6000\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -41.4753 - accuracy: 0.5333 - val_loss: -55.4002 - val_accuracy: 0.6000\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -43.9977 - accuracy: 0.5833 - val_loss: -55.5983 - val_accuracy: 0.6000\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -44.2228 - accuracy: 0.6167 - val_loss: -55.8027 - val_accuracy: 0.6000\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -42.0947 - accuracy: 0.6083 - val_loss: -56.0317 - val_accuracy: 0.6000\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -45.0732 - accuracy: 0.5500 - val_loss: -56.3574 - val_accuracy: 0.6000\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -45.4779 - accuracy: 0.6000 - val_loss: -56.7530 - val_accuracy: 0.6000\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -42.1063 - accuracy: 0.5417 - val_loss: -57.1958 - val_accuracy: 0.6000\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -43.3097 - accuracy: 0.5667 - val_loss: -57.6979 - val_accuracy: 0.6000\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -41.7912 - accuracy: 0.5583 - val_loss: -58.2647 - val_accuracy: 0.6000\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -47.7294 - accuracy: 0.5500 - val_loss: -58.7682 - val_accuracy: 0.6000\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -43.5432 - accuracy: 0.5500 - val_loss: -59.1846 - val_accuracy: 0.6000\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -45.0338 - accuracy: 0.6083 - val_loss: -59.5328 - val_accuracy: 0.6000\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -46.1095 - accuracy: 0.5833 - val_loss: -59.7263 - val_accuracy: 0.6000\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -46.3945 - accuracy: 0.6167 - val_loss: -59.9795 - val_accuracy: 0.6000\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: -44.8927 - accuracy: 0.5083 - val_loss: -60.5700 - val_accuracy: 0.6000\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -47.3827 - accuracy: 0.5250 - val_loss: -61.1048 - val_accuracy: 0.6000\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -48.2225 - accuracy: 0.5917 - val_loss: -61.5533 - val_accuracy: 0.6000\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -45.6873 - accuracy: 0.5333 - val_loss: -61.9444 - val_accuracy: 0.6000\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -49.3767 - accuracy: 0.6167 - val_loss: -62.1993 - val_accuracy: 0.6000\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -42.5142 - accuracy: 0.5083 - val_loss: -62.5070 - val_accuracy: 0.6000\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -44.4918 - accuracy: 0.5333 - val_loss: -62.9027 - val_accuracy: 0.6000\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -49.4875 - accuracy: 0.6250 - val_loss: -63.1683 - val_accuracy: 0.6000\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -51.8077 - accuracy: 0.6333 - val_loss: -63.2219 - val_accuracy: 0.6000\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -47.2232 - accuracy: 0.5167 - val_loss: -63.4261 - val_accuracy: 0.6000\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -49.3345 - accuracy: 0.5750 - val_loss: -63.7670 - val_accuracy: 0.6000\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -52.3083 - accuracy: 0.6000 - val_loss: -64.1593 - val_accuracy: 0.6000\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -52.0463 - accuracy: 0.5583 - val_loss: -64.3778 - val_accuracy: 0.6000\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -49.0228 - accuracy: 0.5417 - val_loss: -64.8023 - val_accuracy: 0.6000\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: -49.1166 - accuracy: 0.5833 - val_loss: -65.4308 - val_accuracy: 0.6000\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -49.7842 - accuracy: 0.5500 - val_loss: -66.0009 - val_accuracy: 0.6000\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -48.8281 - accuracy: 0.5250 - val_loss: -66.5889 - val_accuracy: 0.6000\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -50.5481 - accuracy: 0.5500 - val_loss: -67.1330 - val_accuracy: 0.6000\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: -52.8714 - accuracy: 0.5833 - val_loss: -67.3550 - val_accuracy: 0.6000\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -54.9858 - accuracy: 0.5583 - val_loss: -67.5242 - val_accuracy: 0.6000\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -48.3331 - accuracy: 0.5583 - val_loss: -67.8312 - val_accuracy: 0.6000\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -52.0884 - accuracy: 0.5417 - val_loss: -68.1758 - val_accuracy: 0.6000\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -51.8469 - accuracy: 0.5333 - val_loss: -68.6409 - val_accuracy: 0.6000\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -54.7534 - accuracy: 0.5917 - val_loss: -68.6677 - val_accuracy: 0.6000\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: -52.6872 - accuracy: 0.5500 - val_loss: -68.8173 - val_accuracy: 0.6000\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -51.3292 - accuracy: 0.6083 - val_loss: -69.0633 - val_accuracy: 0.6000\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -52.3763 - accuracy: 0.5667 - val_loss: -69.4374 - val_accuracy: 0.6000\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -54.0046 - accuracy: 0.6167 - val_loss: -69.6917 - val_accuracy: 0.6000\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -53.1040 - accuracy: 0.5917 - val_loss: -70.0990 - val_accuracy: 0.6000\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -52.9955 - accuracy: 0.5250 - val_loss: -70.5847 - val_accuracy: 0.6000\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -52.4198 - accuracy: 0.5750 - val_loss: -70.9841 - val_accuracy: 0.6000\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -51.5751 - accuracy: 0.4583 - val_loss: -71.4404 - val_accuracy: 0.6000\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -53.0601 - accuracy: 0.4833 - val_loss: -72.3211 - val_accuracy: 0.6000\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -55.9945 - accuracy: 0.5750 - val_loss: -72.7745 - val_accuracy: 0.6000\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: -54.5794 - accuracy: 0.5250 - val_loss: -73.1268 - val_accuracy: 0.6000\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -55.7189 - accuracy: 0.5583 - val_loss: -73.4918 - val_accuracy: 0.6000\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -55.8356 - accuracy: 0.6417 - val_loss: -73.5999 - val_accuracy: 0.6000\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -60.5211 - accuracy: 0.5917 - val_loss: -73.6521 - val_accuracy: 0.6000\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -54.6110 - accuracy: 0.5833 - val_loss: -73.7171 - val_accuracy: 0.6000\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -59.2490 - accuracy: 0.5667 - val_loss: -73.6561 - val_accuracy: 0.6000\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -57.8148 - accuracy: 0.5833 - val_loss: -73.7637 - val_accuracy: 0.6000\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -55.4603 - accuracy: 0.5417 - val_loss: -74.2659 - val_accuracy: 0.6000\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -59.0093 - accuracy: 0.5417 - val_loss: -74.8855 - val_accuracy: 0.6000\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -55.6189 - accuracy: 0.5500 - val_loss: -75.4929 - val_accuracy: 0.6000\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -57.3977 - accuracy: 0.5083 - val_loss: -76.1092 - val_accuracy: 0.6000\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -58.8954 - accuracy: 0.5417 - val_loss: -77.1353 - val_accuracy: 0.6000\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -59.2945 - accuracy: 0.5250 - val_loss: -77.7852 - val_accuracy: 0.6000\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -57.2055 - accuracy: 0.6250 - val_loss: -78.2447 - val_accuracy: 0.6000\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -56.6800 - accuracy: 0.5500 - val_loss: -78.6038 - val_accuracy: 0.6000\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -59.8734 - accuracy: 0.5333 - val_loss: -78.9602 - val_accuracy: 0.6000\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -57.5146 - accuracy: 0.6000 - val_loss: -78.9736 - val_accuracy: 0.6000\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: -57.1553 - accuracy: 0.5500 - val_loss: -78.9645 - val_accuracy: 0.6000\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -62.7627 - accuracy: 0.6167 - val_loss: -79.1288 - val_accuracy: 0.6000\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -62.9754 - accuracy: 0.6167 - val_loss: -79.2169 - val_accuracy: 0.6000\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -61.9040 - accuracy: 0.5750 - val_loss: -79.2428 - val_accuracy: 0.6000\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: -56.5175 - accuracy: 0.4917 - val_loss: -79.6831 - val_accuracy: 0.6000\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -58.6981 - accuracy: 0.5250 - val_loss: -80.1950 - val_accuracy: 0.6000\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -59.0973 - accuracy: 0.5417 - val_loss: -80.6597 - val_accuracy: 0.6000\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -65.2364 - accuracy: 0.5667 - val_loss: -81.1496 - val_accuracy: 0.6000\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -67.0117 - accuracy: 0.5417 - val_loss: -81.4324 - val_accuracy: 0.6000\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -62.0995 - accuracy: 0.5500 - val_loss: -81.8686 - val_accuracy: 0.6000\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -65.7286 - accuracy: 0.5417 - val_loss: -82.2258 - val_accuracy: 0.6000\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -63.4381 - accuracy: 0.5000 - val_loss: -82.8403 - val_accuracy: 0.6000\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -64.0192 - accuracy: 0.5833 - val_loss: -83.4076 - val_accuracy: 0.6000\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -67.5302 - accuracy: 0.5667 - val_loss: -83.8620 - val_accuracy: 0.6000\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -64.9441 - accuracy: 0.5000 - val_loss: -84.3304 - val_accuracy: 0.6000\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -59.4461 - accuracy: 0.5083 - val_loss: -85.0077 - val_accuracy: 0.6000\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -64.8608 - accuracy: 0.6083 - val_loss: -85.3907 - val_accuracy: 0.6000\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: -66.3368 - accuracy: 0.5250 - val_loss: -85.6671 - val_accuracy: 0.6000\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -66.3522 - accuracy: 0.5917 - val_loss: -85.5984 - val_accuracy: 0.6000\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -67.0972 - accuracy: 0.5500 - val_loss: -85.7459 - val_accuracy: 0.6000\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -68.6333 - accuracy: 0.5583 - val_loss: -85.9541 - val_accuracy: 0.6000\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -69.6958 - accuracy: 0.5583 - val_loss: -86.2650 - val_accuracy: 0.6000\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -66.7964 - accuracy: 0.5750 - val_loss: -86.3928 - val_accuracy: 0.6000\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: -65.7421 - accuracy: 0.4583 - val_loss: -86.9506 - val_accuracy: 0.6000\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -68.2886 - accuracy: 0.4833 - val_loss: -87.6926 - val_accuracy: 0.6000\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -63.3885 - accuracy: 0.5167 - val_loss: -88.7066 - val_accuracy: 0.6000\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -66.0516 - accuracy: 0.6167 - val_loss: -89.4425 - val_accuracy: 0.6000\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -66.1390 - accuracy: 0.5417 - val_loss: -89.9734 - val_accuracy: 0.6000\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -69.5365 - accuracy: 0.6000 - val_loss: -90.3148 - val_accuracy: 0.6000\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -70.5672 - accuracy: 0.5667 - val_loss: -90.4454 - val_accuracy: 0.6000\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -70.3399 - accuracy: 0.4917 - val_loss: -90.5806 - val_accuracy: 0.6000\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -64.7606 - accuracy: 0.5167 - val_loss: -91.3757 - val_accuracy: 0.6000\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -63.9219 - accuracy: 0.4917 - val_loss: -91.9995 - val_accuracy: 0.6000\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -71.5932 - accuracy: 0.5250 - val_loss: -92.5061 - val_accuracy: 0.6000\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -67.3593 - accuracy: 0.6000 - val_loss: -92.8853 - val_accuracy: 0.6000\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -71.1455 - accuracy: 0.6250 - val_loss: -93.0077 - val_accuracy: 0.6000\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -72.6993 - accuracy: 0.5833 - val_loss: -92.9199 - val_accuracy: 0.6000\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -66.6171 - accuracy: 0.4667 - val_loss: -93.1655 - val_accuracy: 0.6000\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -68.9488 - accuracy: 0.5417 - val_loss: -93.5578 - val_accuracy: 0.6000\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -68.8906 - accuracy: 0.5583 - val_loss: -93.8146 - val_accuracy: 0.6000\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -69.4029 - accuracy: 0.4417 - val_loss: -94.5137 - val_accuracy: 0.6000\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -71.1249 - accuracy: 0.5833 - val_loss: -95.3329 - val_accuracy: 0.6000\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -66.7811 - accuracy: 0.5333 - val_loss: -95.9205 - val_accuracy: 0.6000\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -71.2177 - accuracy: 0.5917 - val_loss: -96.3435 - val_accuracy: 0.6000\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -77.8293 - accuracy: 0.6333 - val_loss: -96.2894 - val_accuracy: 0.6000\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -73.5294 - accuracy: 0.6167 - val_loss: -96.0385 - val_accuracy: 0.6000\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -70.9812 - accuracy: 0.5583 - val_loss: -95.8773 - val_accuracy: 0.6000\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -67.3785 - accuracy: 0.5333 - val_loss: -96.1126 - val_accuracy: 0.6000\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: -71.0038 - accuracy: 0.4667 - val_loss: -96.6187 - val_accuracy: 0.6000\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -79.0457 - accuracy: 0.6000 - val_loss: -97.0980 - val_accuracy: 0.6000\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -75.2074 - accuracy: 0.5500 - val_loss: -97.6368 - val_accuracy: 0.6000\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -70.8121 - accuracy: 0.5250 - val_loss: -98.3032 - val_accuracy: 0.6000\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -75.7925 - accuracy: 0.4417 - val_loss: -99.2316 - val_accuracy: 0.6000\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -76.2642 - accuracy: 0.5750 - val_loss: -99.6560 - val_accuracy: 0.6000\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -76.5403 - accuracy: 0.5333 - val_loss: -100.2623 - val_accuracy: 0.6000\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -78.1424 - accuracy: 0.5250 - val_loss: -100.8721 - val_accuracy: 0.6000\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -78.2282 - accuracy: 0.6167 - val_loss: -101.0907 - val_accuracy: 0.6000\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -78.4424 - accuracy: 0.5167 - val_loss: -101.1989 - val_accuracy: 0.6000\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: -80.3527 - accuracy: 0.4917 - val_loss: -101.4021 - val_accuracy: 0.6000\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -73.0831 - accuracy: 0.5417 - val_loss: -101.5958 - val_accuracy: 0.6000\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -82.0951 - accuracy: 0.5667 - val_loss: -101.7805 - val_accuracy: 0.6000\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -78.8172 - accuracy: 0.5833 - val_loss: -102.0857 - val_accuracy: 0.6000\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -81.9170 - accuracy: 0.5500 - val_loss: -102.4415 - val_accuracy: 0.6000\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -72.5811 - accuracy: 0.4750 - val_loss: -103.0402 - val_accuracy: 0.6000\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -80.1151 - accuracy: 0.5917 - val_loss: -103.4926 - val_accuracy: 0.6000\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -79.2713 - accuracy: 0.5583 - val_loss: -104.0131 - val_accuracy: 0.6000\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -79.9132 - accuracy: 0.5583 - val_loss: -104.3191 - val_accuracy: 0.6000\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -78.5938 - accuracy: 0.5417 - val_loss: -104.8525 - val_accuracy: 0.6000\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -83.0784 - accuracy: 0.5417 - val_loss: -105.2743 - val_accuracy: 0.6000\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -77.7902 - accuracy: 0.5250 - val_loss: -105.5419 - val_accuracy: 0.6000\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -83.4831 - accuracy: 0.5250 - val_loss: -105.9531 - val_accuracy: 0.6000\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -83.2108 - accuracy: 0.5750 - val_loss: -106.2689 - val_accuracy: 0.6000\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -80.3616 - accuracy: 0.5167 - val_loss: -106.9455 - val_accuracy: 0.6000\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: -87.3851 - accuracy: 0.5833 - val_loss: -107.5296 - val_accuracy: 0.6000\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -82.6991 - accuracy: 0.5833 - val_loss: -107.9513 - val_accuracy: 0.6000\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -81.0977 - accuracy: 0.5250 - val_loss: -108.4787 - val_accuracy: 0.6000\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -78.9118 - accuracy: 0.4917 - val_loss: -109.1203 - val_accuracy: 0.6000\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -84.9567 - accuracy: 0.6000 - val_loss: -109.6029 - val_accuracy: 0.6000\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: -76.1299 - accuracy: 0.5250 - val_loss: -110.0348 - val_accuracy: 0.6000\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -82.0482 - accuracy: 0.5167 - val_loss: -110.3878 - val_accuracy: 0.6000\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -83.2371 - accuracy: 0.5917 - val_loss: -110.7892 - val_accuracy: 0.6000\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -84.9767 - accuracy: 0.5250 - val_loss: -111.2793 - val_accuracy: 0.6000\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -82.8198 - accuracy: 0.5000 - val_loss: -111.5747 - val_accuracy: 0.6000\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -84.2880 - accuracy: 0.5750 - val_loss: -111.9065 - val_accuracy: 0.6000\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -86.2449 - accuracy: 0.5000 - val_loss: -112.3060 - val_accuracy: 0.6000\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -91.2361 - accuracy: 0.5250 - val_loss: -112.7381 - val_accuracy: 0.6000\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -86.5902 - accuracy: 0.5667 - val_loss: -113.0881 - val_accuracy: 0.6000\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -83.6026 - accuracy: 0.5583 - val_loss: -113.3076 - val_accuracy: 0.6000\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -87.0370 - accuracy: 0.5417 - val_loss: -113.8644 - val_accuracy: 0.6000\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: -85.8747 - accuracy: 0.5417 - val_loss: -114.3248 - val_accuracy: 0.6000\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -92.2836 - accuracy: 0.5000 - val_loss: -115.0006 - val_accuracy: 0.6000\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -87.8270 - accuracy: 0.5500 - val_loss: -115.4838 - val_accuracy: 0.6000\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -86.6913 - accuracy: 0.5583 - val_loss: -115.8623 - val_accuracy: 0.6000\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -89.5087 - accuracy: 0.5000 - val_loss: -116.4716 - val_accuracy: 0.6000\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -87.3496 - accuracy: 0.5250 - val_loss: -117.0438 - val_accuracy: 0.6000\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -92.8192 - accuracy: 0.5917 - val_loss: -117.3777 - val_accuracy: 0.6000\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -86.0588 - accuracy: 0.5500 - val_loss: -118.0713 - val_accuracy: 0.6000\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -90.1809 - accuracy: 0.5083 - val_loss: -118.6543 - val_accuracy: 0.6000\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -83.1600 - accuracy: 0.5417 - val_loss: -119.3352 - val_accuracy: 0.6000\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -91.6503 - accuracy: 0.5500 - val_loss: -119.7527 - val_accuracy: 0.6000\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -83.1806 - accuracy: 0.5333 - val_loss: -120.4880 - val_accuracy: 0.6000\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -95.2874 - accuracy: 0.5917 - val_loss: -120.8151 - val_accuracy: 0.6000\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: -96.5166 - accuracy: 0.5583 - val_loss: -121.0883 - val_accuracy: 0.6000\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -95.2825 - accuracy: 0.5500 - val_loss: -121.1790 - val_accuracy: 0.6000\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -94.9575 - accuracy: 0.5917 - val_loss: -121.2898 - val_accuracy: 0.6000\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -92.2625 - accuracy: 0.5250 - val_loss: -121.3079 - val_accuracy: 0.6000\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: -95.3180 - accuracy: 0.5833 - val_loss: -121.7001 - val_accuracy: 0.6000\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -89.2613 - accuracy: 0.4750 - val_loss: -122.2940 - val_accuracy: 0.6000\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -90.8283 - accuracy: 0.5250 - val_loss: -123.2615 - val_accuracy: 0.6000\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -90.0120 - accuracy: 0.5417 - val_loss: -124.0151 - val_accuracy: 0.6000\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -91.9305 - accuracy: 0.5667 - val_loss: -124.6865 - val_accuracy: 0.6000\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: -89.7250 - accuracy: 0.5000 - val_loss: -125.1218 - val_accuracy: 0.6000\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: -92.2569 - accuracy: 0.5083 - val_loss: -125.5371 - val_accuracy: 0.6000\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -92.2294 - accuracy: 0.5417 - val_loss: -125.7658 - val_accuracy: 0.6000\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -89.5409 - accuracy: 0.5000 - val_loss: -126.2094 - val_accuracy: 0.6000\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -97.7041 - accuracy: 0.6333 - val_loss: -126.3117 - val_accuracy: 0.6000\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -96.6283 - accuracy: 0.5333 - val_loss: -126.4241 - val_accuracy: 0.6000\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -100.6403 - accuracy: 0.5333 - val_loss: -126.5238 - val_accuracy: 0.6000\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -93.9877 - accuracy: 0.5333 - val_loss: -126.7814 - val_accuracy: 0.6000\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -96.6393 - accuracy: 0.5500 - val_loss: -126.7529 - val_accuracy: 0.6000\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -97.0170 - accuracy: 0.4667 - val_loss: -127.4291 - val_accuracy: 0.6000\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: -92.5514 - accuracy: 0.5083 - val_loss: -128.0506 - val_accuracy: 0.6000\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -98.5801 - accuracy: 0.5917 - val_loss: -128.6575 - val_accuracy: 0.6000\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -99.4950 - accuracy: 0.5833 - val_loss: -128.8445 - val_accuracy: 0.6000\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -103.1407 - accuracy: 0.5000 - val_loss: -129.2782 - val_accuracy: 0.6000\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -105.4621 - accuracy: 0.5667 - val_loss: -129.9621 - val_accuracy: 0.6000\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -105.8299 - accuracy: 0.5917 - val_loss: -130.4515 - val_accuracy: 0.6000\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -99.7494 - accuracy: 0.5417 - val_loss: -130.9119 - val_accuracy: 0.6000\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -98.5715 - accuracy: 0.5250 - val_loss: -131.6775 - val_accuracy: 0.6000\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -96.1197 - accuracy: 0.5417 - val_loss: -132.2153 - val_accuracy: 0.6000\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: -100.4170 - accuracy: 0.5583 - val_loss: -132.7538 - val_accuracy: 0.6000\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -95.4981 - accuracy: 0.5083 - val_loss: -133.5007 - val_accuracy: 0.6000\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -95.9790 - accuracy: 0.5333 - val_loss: -134.0624 - val_accuracy: 0.6000\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -103.5382 - accuracy: 0.5667 - val_loss: -134.8807 - val_accuracy: 0.6000\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -107.4705 - accuracy: 0.5417 - val_loss: -135.1524 - val_accuracy: 0.6000\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -104.6621 - accuracy: 0.5667 - val_loss: -135.3599 - val_accuracy: 0.6000\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -107.8679 - accuracy: 0.5917 - val_loss: -135.4332 - val_accuracy: 0.6000\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -108.5151 - accuracy: 0.5750 - val_loss: -135.3943 - val_accuracy: 0.6000\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -98.5571 - accuracy: 0.5250 - val_loss: -135.4446 - val_accuracy: 0.6000\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -114.3411 - accuracy: 0.5417 - val_loss: -136.0308 - val_accuracy: 0.6000\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -104.4036 - accuracy: 0.4833 - val_loss: -136.5930 - val_accuracy: 0.6000\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -106.8359 - accuracy: 0.5000 - val_loss: -137.4740 - val_accuracy: 0.6000\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -105.3857 - accuracy: 0.5333 - val_loss: -138.4742 - val_accuracy: 0.6000\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -97.9372 - accuracy: 0.5000 - val_loss: -139.5110 - val_accuracy: 0.6000\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -108.5011 - accuracy: 0.5000 - val_loss: -140.3941 - val_accuracy: 0.6000\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -109.5435 - accuracy: 0.5417 - val_loss: -140.9857 - val_accuracy: 0.6000\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -106.3443 - accuracy: 0.5083 - val_loss: -141.6349 - val_accuracy: 0.6000\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -102.0340 - accuracy: 0.5167 - val_loss: -142.4041 - val_accuracy: 0.6000\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -102.7415 - accuracy: 0.5083 - val_loss: -142.6301 - val_accuracy: 0.6000\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: -110.2797 - accuracy: 0.5500 - val_loss: -142.7539 - val_accuracy: 0.6000\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -110.8962 - accuracy: 0.5417 - val_loss: -142.6610 - val_accuracy: 0.6000\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: -97.7196 - accuracy: 0.4583 - val_loss: -143.1321 - val_accuracy: 0.6000\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -103.4016 - accuracy: 0.5333 - val_loss: -143.4381 - val_accuracy: 0.6000\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: -108.5203 - accuracy: 0.4917 - val_loss: -143.8549 - val_accuracy: 0.6000\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -111.3525 - accuracy: 0.6167 - val_loss: -144.1076 - val_accuracy: 0.6000\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: -109.0810 - accuracy: 0.5000 - val_loss: -144.5028 - val_accuracy: 0.6000\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -110.7529 - accuracy: 0.5500 - val_loss: -144.6232 - val_accuracy: 0.6000\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -109.1912 - accuracy: 0.5750 - val_loss: -144.8365 - val_accuracy: 0.6000\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -108.0367 - accuracy: 0.5417 - val_loss: -145.2642 - val_accuracy: 0.6000\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: -112.5972 - accuracy: 0.5333 - val_loss: -146.1101 - val_accuracy: 0.6000\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -103.2148 - accuracy: 0.4917 - val_loss: -147.0527 - val_accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "#compiling the ann using stochastic gradient descent (optimizer - adam)\n",
    "\n",
    "ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#setting callback for monitoring maximum accuracy\n",
    "\n",
    "from tabnanny import verbose\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',mode = 'min',verbose=1,patience=25)\n",
    "\n",
    "#traiining the ann with batch size of 32 (this is a batch learning)\n",
    "\n",
    "model = ann.fit(x_train,y_train,batch_size=32,validation_data=(x_test,y_test),epochs=500,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42ac2bbbda3723635b4d79812a5d5c7fd30e1eda2aeaadb4b3ca1545733c2df7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
